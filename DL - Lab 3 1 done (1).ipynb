{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5dac8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e383e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor(2)\n",
      "y: tensor(10)\n",
      "w: tensor(3., requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Create tensor without requires_grad = True\n",
    "x = torch.tensor(2) # Input tensor\n",
    "y = torch.tensor(10) # Ground-Truth / Target\n",
    "\n",
    "# Create tensors with requires_grad = True\n",
    "w = torch.tensor(3.0, requires_grad=True) # Weights\n",
    "\n",
    "# Print the tensors\n",
    "print(\"x:\", x)\n",
    "print(\"y:\", y)\n",
    "print(\"w:\", w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e756b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat: tensor(6., grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Define a function y_hat for the tensors\n",
    "y_hat = w * x # Output / Predictions\n",
    "\n",
    "print(\"y_hat:\", y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e4c177d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(16., grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Compute loss\n",
    "s = y_hat - y\n",
    "loss = (s)**2\n",
    "\n",
    "print(\"Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dc35532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes the gradients for all tensors that have requires_grad=True, by calling the backward function for loss\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbb3bc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad : None\n",
      "w.grad : tensor(-16.)\n"
     ]
    }
   ],
   "source": [
    "# Access and print the gradients with respect to x and w\n",
    "dx = x.grad  # x does not have requires_grad=True, so dx will be None\n",
    "dw = w.grad  # w has requires_grad=True, so dw will contain the gradient\n",
    "\n",
    "print(\"x.grad :\", dx)\n",
    "print(\"w.grad :\", dw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e54fba2-b34a-46b1-85c8-a283411171e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2d733c3-85e1-4f5f-9f3f-9c0e74f814ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat: tensor(17., grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "b=torch.tensor(11.0, requires_grad=True)\n",
    "y_hat=w*x+b\n",
    "print(\"y_hat:\", y_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "297a7c66-6edd-4f8d-ab96-ebc409a5d401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(49., grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "s = y_hat - y\n",
    "loss = (s)**2\n",
    "\n",
    "print(\"Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6e82e06-927f-41d6-a51e-a5cba70db869",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93bf47bc-2272-4f54-8dae-eed6d64c9cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad : None\n",
      "b.grad : tensor(14.)\n",
      "w.grad : tensor(28.)\n"
     ]
    }
   ],
   "source": [
    "db=b.grad\n",
    "dw = w.grad  \n",
    "\n",
    "print(\"x.grad :\", dx)\n",
    "print(\"b.grad :\", db)\n",
    "print(\"w.grad :\", dw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a0adf7d-4164-4dd2-8048-0cdb0e8731c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "b.grad.data.zero_()\n",
    "w.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9319ebf-601b-4dd6-9c40-c7cb620dab2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat: tensor(12.5000, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y_hat=w*x**2 + 1/2\n",
    "print(\"y_hat:\", y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b75db8b-5c2b-4ac4-bf50-976c8cec4d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(6.2500, grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "s = y_hat - y\n",
    "loss = (s)**2\n",
    "\n",
    "print(\"Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1207a461-ed53-4665-83d7-b150ce6f68bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad : None\n",
      "w.grad : tensor(20.)\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "dx = x.grad \n",
    "dw = w.grad  \n",
    "\n",
    "print(\"x.grad :\", dx)\n",
    "print(\"w.grad :\", dw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90ca6648-e22d-41f2-adf6-a471f3badaab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "w.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70fd6baf-e7db-4f91-8c2f-c74f1b92b62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat: tensor(24., grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y_hat=x**3 + w*x**2 + 2*x\n",
    "print(\"y_hat:\", y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "952b55e0-84b9-4289-9da5-9aaa42f6f934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(196., grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "s = y_hat - y\n",
    "loss = (s)**2\n",
    "\n",
    "print(\"Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7869680a-3ce3-481f-8473-b53b7faed2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad : None\n",
      "w.grad : tensor(112.)\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "dx = x.grad \n",
    "dw = w.grad  \n",
    "\n",
    "print(\"x.grad :\", dx)\n",
    "print(\"w.grad :\", dw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef69c2a3-0588-4675-939c-b4834bec3c15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
